{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d6a1b1",
   "metadata": {},
   "source": [
    "\n",
    "# Multilingual ACE Training & Deployment Notebook\n",
    "\n",
    "This notebook contains a ready-to-run project flow to train and deploy the ACE (Advanced Cyberbullying & Emotion Detection) fusion model for detecting women's harassment and cyber abuse in social media comments (English, Tamil, Malayalam).\n",
    "\n",
    "Sections: Module 1 to Module 9. Follow the cells in order. Some cells contain optional heavy operations (model training) which you should run on a GPU-enabled environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332bd63",
   "metadata": {},
   "source": [
    "## Module 1: Data Collection\n",
    "\n",
    "Collect multilingual social media comments from APIs (Facebook Graph API, Twitter API v2, YouTube Data API) and open datasets such as HASOC, DravidianLangTech, and OLID. Save each record with fields: `comment_text`, `language`, `label`.\n",
    "\n",
    "Below are example helper functions for aggregating data and saving to CSV. Replace placeholders with your API keys and dataset paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Aggregate local open datasets and save as unified CSV\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_and_merge_datasets(dataset_paths):\n",
    "    dfs = []\n",
    "    for p in dataset_paths:\n",
    "        df = pd.read_csv(p)\n",
    "        # Expect at least columns: text, label, optional language\n",
    "        if 'text' not in df.columns:\n",
    "            raise ValueError(f'Missing text column in {p}')\n",
    "        if 'label' not in df.columns:\n",
    "            # if label column missing, try to map existing columns or skip\n",
    "            raise ValueError(f'Missing label column in {p}')\n",
    "        cols = ['text','label'] + ([c for c in df.columns if c=='language'])\n",
    "        cols = [c for c in cols if c in df.columns]\n",
    "        dfs.append(df[cols])\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Example usage (update paths)\n",
    "# dataset_paths = ['data/hasoc.csv', 'data/dravidian.csv', 'data/olid.csv']\n",
    "# merged = load_and_merge_datasets(dataset_paths)\n",
    "# merged.to_csv('data/multilingual_comments_raw.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f1697",
   "metadata": {},
   "source": [
    "## Module 2: Data Preprocessing\n",
    "\n",
    "Tasks: language detection, cleaning (remove URLs, mentions, emojis managed separately), optional transliteration for Tamil & Malayalam, tokenization, stopword removal, emoji demojize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing utilities\n",
    "import re\n",
    "import pandas as pd\n",
    "import emoji\n",
    "try:\n",
    "    from langdetect import detect\n",
    "except Exception:\n",
    "    def detect(x):\n",
    "        return 'en'\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\\\S+|www\\\\.\\\\S+', '', text)\n",
    "    # Remove mentions and hashtags (keep words)\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def demojize_text(text):\n",
    "    return emoji.demojize(text)\n",
    "\n",
    "def detect_language_safe(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except Exception:\n",
    "        return 'en'\n",
    "\n",
    "# Example pipeline on a CSV\n",
    "\n",
    "def preprocess_csv(input_csv, output_csv, transliterate=False):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    if 'language' not in df.columns:\n",
    "        df['language'] = df['text'].fillna('').astype(str).apply(detect_language_safe)\n",
    "    df['clean_text'] = df['text'].fillna('').astype(str).apply(clean_text)\n",
    "    df['demojized'] = df['clean_text'].apply(demojize_text)\n",
    "    # Optional transliteration hook - user can plug in indic_transliteration here\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    return df\n",
    "\n",
    "# Example usage (uncomment to run)\n",
    "# df = preprocess_csv('data/multilingual_comments_raw.csv', 'data/multilingual_comments_cleaned.csv')\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee5be5",
   "metadata": {},
   "source": [
    "## Module 3: Feature Extraction\n",
    "\n",
    "Extract model-specific features:\n",
    "- CNN: character & n-gram embeddings\n",
    "- BERT: tokenized inputs via mBERT / IndicBERT tokenizer\n",
    "- SVM: TF-IDF features\n",
    "- Emotion: emotion vectors via a pretrained emotion model\n",
    "\n",
    "Examples below show how to create TF-IDF, tokenized datasets, and a placeholder for emotion extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction examples\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "def build_tfidf(texts, max_features=10000):\n",
    "    vect = TfidfVectorizer(max_features=max_features, ngram_range=(1,2))\n",
    "    X = vect.fit_transform(texts)\n",
    "    return vect, X\n",
    "\n",
    "def get_bert_tokenizer(model_name='bert-base-multilingual-cased'):\n",
    "    return AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Placeholder for emotion extraction - user can plug DeepMoji/DeepEmoji or a transformer emotion model\n",
    "def extract_emotion_vectors(texts):\n",
    "    # returns list of float vectors (e.g., anger, joy, sadness, disgust) per text\n",
    "    return [np.zeros(4).tolist() for _ in texts]\n",
    "\n",
    "# Example usage\n",
    "# vect, X = build_tfidf(df['demojized'].tolist())\n",
    "# tokenizer = get_bert_tokenizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92b52f",
   "metadata": {},
   "source": [
    "## Module 4: Model Training\n",
    "\n",
    "Train CNN, BERT, SVM, and Emotion models separately. The repository already contains trainer classes for BERT and CNN (`models/bert_model.py`, `models/cnn_model.py`) and the ACE ensemble (`models/ensemble.py`). The example below shows how to use `train/train_pipeline.py` or the new `train/multilingual_training_runner.py` to run a full training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full training using the ACETrainer via the multilingual runner (recommended)\n",
    "# This cell invokes the runner script programmatically. For heavy training, run via CLI on a GPU machine.\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "data_csv = 'data/processed/multilingual_processed.csv'\n",
    "if Path(data_csv).exists():\n",
    "    print('Starting training runner (this may take a long time on CPU)')\n",
    "    # Example CLI call (uncomment to run)\n",
    "    # subprocess.run(['python', 'train/multilingual_training_runner.py', '--data', data_csv, '--config', 'deployment/config_multilingual.yaml'])\n",
    "else:\n",
    "    print('Processed training CSV not found. Run preprocessing cells first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92621eef",
   "metadata": {},
   "source": [
    "## Module 5: ACE Fusion Layer\n",
    "\n",
    "Implement the ACE fusion algorithm to combine model outputs. The repository `models/ensemble.py` already provides an `ACEEnsemble` class. Below is a conceptual example to compute a weighted fusion and learn weights via grid search or simple optimization to minimize false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simple weight learning via grid search (toy example)\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_weights(base_scores, labels, weights):\n",
    "    # base_scores: dict of arrays: {'bert': [...], 'cnn': [...], 'emotion': [...], 'svm': [...]} \n",
    "    scores = np.zeros_like(base_scores['bert'])\n",
    "    for k,w in weights.items():\n",
    "        scores += w * np.array(base_scores[k])\n",
    "    preds = (scores >= 0.5).astype(int)\n",
    "    return f1_score(labels, preds), precision_score(labels, preds), recall_score(labels, preds)\n",
    "\n",
    "# Example usage with dummy data\n",
    "# base_scores = {'bert': np.random.rand(100), 'cnn': np.random.rand(100), 'emotion': np.random.rand(100), 'svm': np.random.rand(100)}\n",
    "# labels = np.random.randint(0,2,100)\n",
    "# weights = {'bert':0.4,'cnn':0.2,'emotion':0.3,'svm':0.1}\n",
    "# print(evaluate_weights(base_scores, labels, weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2777615",
   "metadata": {},
   "source": [
    "## Module 6: Women Harassment Detection Layer\n",
    "\n",
    "Fine-tune a multilingual BERT (mBERT / IndicBERT) specifically on women harassment examples. This model acts as an additional specialized detector and its score can be used in the ACE fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning outline (use models/bert_model.py trainer)\n",
    "from models.bert_model import create_bert_model, BERTAbuseDataset, BERTAbuseDetectorTrainer\n",
    "\n",
    "config = {'model_name':'bert-base-multilingual-cased', 'max_length':256, 'batch_size':16}\n",
    "model, tokenizer = create_bert_model(config)\n",
    "trainer = BERTAbuseDetectorTrainer(model, tokenizer, device='cuda' if __import__('torch').cuda.is_available() else 'cpu')\n",
    "# Prepare dataset where 'women_harassment' label is used to fine-tune the specialized model\n",
    "# dataset = BERTAbuseDataset(women_texts, women_labels, tokenizer, max_length=256)\n",
    "# trainer.train(train_loader, val_loader, num_epochs=3, learning_rate=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193ba6b",
   "metadata": {},
   "source": [
    "## Module 7: Output & Evaluation\n",
    "\n",
    "Evaluate each model and the fusion layer. Use accuracy, precision, recall, F1. Display sample predictions with confidence, language, and emotion. Visualize confusion matrices and metric trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example evaluation using ACEEnsemble (if trained and saved)\n",
    "from models.ensemble import create_ace_ensemble\n",
    "import json\n",
    "\n",
    "# Load config and create ensemble\n",
    "with open('deployment/config_multilingual.yaml') as f:\n",
    "    import yaml\n",
    "    cfg = yaml.safe_load(f)\n",
    "ace = create_ace_ensemble(cfg)\n",
    "# ace.load_model('models/saved/ace_ensemble')  # load if available\n",
    "\n",
    "# Example single prediction\n",
    "sample = 'Nee loosu ponnu da 😏'\n",
    "print(ace.predict_single(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d3af9",
   "metadata": {},
   "source": [
    "## Module 8: API Integration\n",
    "\n",
    "Wrap the trained ACE model into a FastAPI REST API. The repository already contains `api/serve.py` which uses `ACEAPIServer`. Example usage below shows how to run the API locally and test the `/predict` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the server (example)\n",
    "# In a terminal, run:\n",
    "# uvicorn api.serve:app --host 0.0.0.0 --port 8000 --reload\n",
    "\n",
    "# Example: test predict endpoint\n",
    "import requests\n",
    "\n",
    "# url = 'http://127.0.0.1:8000/predict'\n",
    "# payload = {'text':'Nee loosu ponnu da 😏', 'include_explanation':True, 'include_preprocessing':True}\n",
    "# r = requests.post(url, json=payload)\n",
    "# print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86b91f",
   "metadata": {},
   "source": [
    "## Module 9: Future Enhancements\n",
    "\n",
    "Stubs and ideas for audio/video detection (Whisper for speech->text, Vision Transformer for facial expression), multimodal fusion, and real-time plugins for social platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio processing with Whisper\n",
    "def process_audio(audio_file):\n",
    "    \"\"\"\n",
    "    Stub for audio processing using Whisper ASR\n",
    "    \"\"\"\n",
    "    # TODO: Implement Whisper ASR integration\n",
    "    # import whisper\n",
    "    # model = whisper.load_model(\"base\")\n",
    "    # result = model.transcribe(audio_file)\n",
    "    # return result[\"text\"]\n",
    "    pass\n",
    "\n",
    "# Video processing with Vision Transformer\n",
    "def process_video(video_file):\n",
    "    \"\"\"\n",
    "    Stub for video processing using Vision Transformer\n",
    "    \"\"\"\n",
    "    # TODO: Implement Vision Transformer for facial expression analysis\n",
    "    # from transformers import pipeline\n",
    "    # classifier = pipeline(\"image-classification\", model=\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "    # Process video frames and analyze expressions\n",
    "    pass\n",
    "\n",
    "# Multimodal fusion\n",
    "def multimodal_fusion(text_score, audio_score, video_score):\n",
    "    \"\"\"\n",
    "    Stub for fusing predictions from multiple modalities\n",
    "    \"\"\"\n",
    "    # TODO: Implement weighted fusion of predictions\n",
    "    # weights = [0.6, 0.2, 0.2]  # Example weights for text, audio, video\n",
    "    # final_score = np.average([text_score, audio_score, video_score], weights=weights)\n",
    "    # return final_score\n",
    "    pass\n",
    "\n",
    "# Social media plugin interfaces\n",
    "class SocialMediaPlugin:\n",
    "    \"\"\"\n",
    "    Base class for social media platform integrations\n",
    "    \"\"\"\n",
    "    def __init__(self, platform):\n",
    "        self.platform = platform\n",
    "    \n",
    "    def connect(self):\n",
    "        \"\"\"Establish connection to platform API\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def monitor(self):\n",
    "        \"\"\"Monitor content stream\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def alert(self, content, prediction):\n",
    "        \"\"\"Send alerts for detected harassment\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c994408",
   "metadata": {},
   "source": [
    "### Implementation Notes\n",
    "\n",
    "1. **Audio Processing**\n",
    "   - Whisper ASR can handle multilingual speech recognition\n",
    "   - Supports 96+ languages including English, Tamil, Malayalam\n",
    "   - Can detect emotional tone from speech patterns\n",
    "\n",
    "2. **Video Analysis**\n",
    "   - Vision Transformer for facial expression recognition\n",
    "   - Frame-by-frame analysis with temporal aggregation\n",
    "   - Optional: Action recognition for gesture analysis\n",
    "\n",
    "3. **Multimodal Fusion**\n",
    "   - Weighted combination of predictions from different modalities\n",
    "   - Adaptive weights based on confidence scores\n",
    "   - Late fusion strategy for flexibility\n",
    "\n",
    "4. **Social Media Integration**\n",
    "   - Plugin architecture for different platforms\n",
    "   - Real-time monitoring and alert system\n",
    "   - Privacy-preserving analysis pipeline\n",
    "\n",
    "These enhancements would make the harassment detection system more robust by considering multiple modalities of communication and enabling real-time monitoring across social platforms."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
